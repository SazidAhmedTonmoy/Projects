{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(\"../input/ocular-disease-recognition-odir5k/preprocessed_images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/ocular-disease-recognition-odir5k/full_df.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "f = plt.figure(figsize=(50,20))\n",
    "for Class in df['labels'].unique():\n",
    "    seg = df[df['labels']==Class]\n",
    "    address = seg.sample().iloc[0]['filename']\n",
    "    dataset_dir = \"/kaggle/input/ocular-disease-recognition-odir5k/preprocessed_images/\"\n",
    "    img = cv2.imread(dataset_dir+ address)\n",
    "    #print(img)\n",
    "    ax = f.add_subplot(2, 4,count)\n",
    "    ax = plt.imshow(img)\n",
    "    ax = plt.title(Class,fontsize= 30)\n",
    "    count = count + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_myopia(text):\n",
    "    if \"myopia\" in text:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"left_myopia\"] = df[\"Left-Diagnostic Keywords\"].apply(lambda x: has_myopia(x))\n",
    "df[\"right_myopia\"] = df[\"Right-Diagnostic Keywords\"].apply(lambda x: has_myopia(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_myopia_imgs = []\n",
    "right_myopia_imgs = []\n",
    "for i in range(len(df)):\n",
    "    if df[\"left_myopia\"][i] == 1:\n",
    "        left_myopia_imgs.append(df['Left-Fundus'][i])\n",
    "    if df[\"right_myopia\"][i] == 1:\n",
    "        right_myopia_imgs.append(df['Right-Fundus'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(left_myopia_imgs))\n",
    "print(len(right_myopia_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_normal(text):\n",
    "    if \"normal fundus\" in text:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"left_normal\"] = df[\"Left-Diagnostic Keywords\"].apply(lambda x: is_normal(x))\n",
    "df[\"right_normal\"] = df[\"Right-Diagnostic Keywords\"].apply(lambda x: is_normal(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_normal_imgs = []\n",
    "right_normal_imgs = []\n",
    "for i in range(len(df)):\n",
    "    if df[\"left_normal\"][i] == 1:\n",
    "        left_normal_imgs.append(df['Left-Fundus'][i])\n",
    "    if df[\"right_normal\"][i] == 1:\n",
    "        right_normal_imgs.append(df['Right-Fundus'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(left_normal_imgs))\n",
    "print(len(right_normal_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "left_normal_imgs = random.sample(left_normal_imgs, 304)\n",
    "right_normal_imgs = random.sample(right_normal_imgs, 290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(left_normal_imgs))\n",
    "print(len(right_normal_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myopia = np.concatenate((left_myopia_imgs,right_myopia_imgs),axis=0)\n",
    "normal = np.concatenate((left_normal_imgs,right_normal_imgs),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(myopia),len(normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"../input/ocular-disease-recognition-odir5k/preprocessed_images/\"\n",
    "image_size=224\n",
    "labels = []\n",
    "dataset = []\n",
    "def create_dataset(image_category,label):\n",
    "    for img in image_category:\n",
    "        image_path = os.path.join(images_dir,img)\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image,(image_size,image_size))\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        dataset.append([np.array(image),np.array(label)])\n",
    "    random.shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "dataset = create_dataset(myopia,1)\n",
    "dataset = create_dataset(normal,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in dataset]).reshape(-1,image_size,image_size,3)\n",
    "Y = np.array([i[1] for i in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-50:]\n",
    "Y_val = Y_train[-50:]\n",
    "X_train = X_train[:-50]\n",
    "Y_train = Y_train[:-50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train Shape: {X_train.shape}, Y_train Shape: {Y_train.shape}\")\n",
    "print(f\"X_val Shape: {X_val.shape}, Y_val Shape: {Y_val.shape}\")\n",
    "print(f\"X_test Shape: {X_test.shape}, Y_test Shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "resnet = ResNet50(weights=\"imagenet\", include_top = False, input_shape=(image_size,image_size,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(resnet)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\",patience=7, verbose=1)\n",
    "callbacks = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, Y_train, batch_size=8, epochs=100, validation_data=(X_val, Y_val),\n",
    "                    verbose=1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, batch_size=8)\n",
    "y_pred[y_pred <= 0.5] = 0.\n",
    "y_pred[y_pred > 0.5] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
